# defino la clase binaria
dataset[, clase01 := ifelse(clase_ternaria %in% c("BAJA+1", "BAJA+2"), 1, 0)]
campos_buenos <- setdiff(colnames(dataset), c("clase_ternaria", "clase01"))
# genero un modelo para cada uno de las modelos_qty MEJORES
# iteraciones de la Bayesian Optimization
vganancias_suavizadas <- c()
imodelo <- 0L
modelo_rank=1
imodelo <- 0L
imodelo <- imodelo + 1L
cat("\nmodelo_rank: ", modelo_rank, ", semillas: ")
OUTPUT$status$modelo_rank <- modelo_rank
parametros <- as.list(copy(tb_log[modelo_rank]))
iteracion_bayesiana <- parametros$iteracion_bayesiana
# creo CADA VEZ el dataset de lightgbm
dtrain <- lgb.Dataset(
data = data.matrix(dataset[, campos_buenos, with = FALSE]),
label = dataset[, clase01],
weight = dataset[, ifelse(clase_ternaria %in% c("BAJA+2"), 1.0000001, 1.0)],
free_raw_data = FALSE
)
ganancia <- parametros$ganancia
# elimino los parametros que no son de lightgbm
parametros$experimento <- NULL
parametros$cols <- NULL
parametros$rows <- NULL
parametros$fecha <- NULL
parametros$estimulos <- NULL
parametros$ganancia <- NULL
parametros$iteracion_bayesiana <- NULL
if (future_con_clase) {
tb_ganancias <-
as.data.table(list("envios" = 1:1:PARAM$graficar$envios_hasta))
tb_ganancias[, gan_sum := 0.0]
}
View(tb_ganancias)
PARAM$semillas
vsemilla=123457
sem <- 0L
sem <- sem + 1L
cat(sem, " ")
OUTPUT$status$sem <- sem
GrabarOutput()
# Utilizo la semilla definida en este script
parametros$seed <- vsemilla
nombre_raiz <- paste0(
sprintf("%02d", modelo_rank),
"_",
sprintf("%03d", iteracion_bayesiana),
"_s",
parametros$seed
)
arch_modelo <- paste0(
"modelo_",
#	  PARAM$version,"_",
nombre_raiz,
".model"
)
# genero el modelo entrenando en los datos finales
set.seed(parametros$seed, kind = "L'Ecuyer-CMRG")
modelo_final <- lightgbm(
data = dtrain,
param = parametros,
verbose = -100
)
# grabo el modelo, achivo .model
lgb.save(modelo_final,
file = arch_modelo
)
arch_modelo
# creo y grabo la importancia de variables
tb_importancia <- as.data.table(lgb.importance(modelo_final))
fwrite(tb_importancia,
file = paste0(
"impo_",
#       nombre_raiz,
".txt"
),
sep = "\t"
)
fwrite(tb_importancia,
file = paste0(
"impo_",
nombre_raiz,
".txt"
),
sep = "\t"
)
# genero la prediccion, Scoring
prediccion <- predict(
modelo_final,
data.matrix(dfuture[, campos_buenos, with = FALSE])
)
tb_prediccion <-
dfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]
tb_prediccion[, prob := prediccion]
View(tb_prediccion)
nom_pred <- paste0(
"pred_",
PARAM$version,"_",
nombre_raiz,
".csv"
)
nom_pred
fwrite(
tb_prediccion[, list(numero_de_cliente, foto_mes, prob, clase_ternaria)],
file = nom_pred,
sep = ","    # Tenía "\t" no se porqué
)
View(tb_prediccion)
# genero los archivos para Kaggle
cortes <- seq(
from = PARAM$kaggle$envios_desde,
to = PARAM$kaggle$envios_hasta,
by = PARAM$kaggle$envios_salto
)
setorder(tb_prediccion, -prob)
if (!future_con_clase) {
# genero los archivos para Kaggle
for (corte in cortes)
{
tb_prediccion[, Predicted := 0L]
tb_prediccion[1:corte, Predicted := 1L]
nom_submit <- paste0(
PARAM$experimento,
"_",
nombre_raiz,
"_",
sprintf("%05d", corte),
".csv"
)
fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],
file = nom_submit,
sep = ","
)
}
}
if (future_con_clase) {
tb_prediccion[, ganancia_acum :=
cumsum(ifelse(clase_ternaria == "BAJA+2", 117000, -3000))]
tb_ganancias[, paste0("g", sem) :=
tb_prediccion[1:PARAM$graficar$envios_hasta, ganancia_acum]]
tb_ganancias[, gan_sum :=
gan_sum + tb_prediccion[1:PARAM$graficar$envios_hasta, ganancia_acum]]
}
# borro y limpio la memoria para la vuelta siguiente del for
rm(tb_prediccion)
rm(tb_importancia)
rm(modelo_final)
gc()
if (future_con_clase) {
qsemillas <- length(PARAM$semillas)
tb_ganancias[, gan_sum := gan_sum / qsemillas]
# calculo la mayor ganancia  SUAVIZADA
tb_ganancias[, gan_suavizada := frollmean(
x = gan_sum,
n = PARAM$graficar$ventana_suavizado,
align = "center",
na.rm = TRUE,
hasNA = TRUE
)]
ganancia_suavizada_max <- tb_ganancias[, max(gan_suavizada, na.rm = TRUE)]
vganancias_suavizadas <- c(vganancias_suavizadas, ganancia_suavizada_max)
ymax <- max(tb_ganancias, na.rm = TRUE)
campos_ganancias <- setdiff(colnames(tb_ganancias), "envios")
ymin <- min(tb_ganancias[envios >= PARAM$graficar$envios_desde, campos_ganancias, with=FALSE ],
na.rm = TRUE
)
arch_grafico <- paste0(
"modelo_",
sprintf("%02d", modelo_rank),
"_",
sprintf("%03d", iteracion_bayesiana),
".pdf"
)
pdf(arch_grafico)
plot(
x = tb_ganancias[envios >= PARAM$graficar$envios_desde, envios],
y = tb_ganancias[envios >= PARAM$graficar$envios_desde, g1],
type = "l",
col = "gray",
xlim = c(PARAM$graficar$envios_desde, PARAM$graficar$envios_hasta),
ylim = c(ymin, ymax),
main = paste0("Mejor gan prom = ", as.integer(ganancia_suavizada_max)),
xlab = "Envios",
ylab = "Ganancia",
panel.first = grid()
)
# las siguientes curvas
if (qsemillas > 1) {
for (s in 2:qsemillas)
{
lines(
x = tb_ganancias[envios >= PARAM$graficar$envios_desde, envios],
y = tb_ganancias[envios >= PARAM$graficar$envios_desde, get(paste0("g", s))],
col = "gray"
)
}
}
# finalmente la curva promedio
lines(
x = tb_ganancias[envios >= PARAM$graficar$envios_desde, envios],
y = tb_ganancias[envios >= PARAM$graficar$envios_desde, gan_sum],
col = "red"
)
dev.off()
# grabo las ganancias, para poderlas comparar con OTROS modelos
arch_ganancias <- paste0(
"ganancias_",
sprintf("%02d", modelo_rank),
"_",
sprintf("%03d", iteracion_bayesiana),
".txt"
)
fwrite(tb_ganancias,
file = arch_ganancias,
sep = "\t",
)
rm(tb_ganancias)
gc()
}
# impresion ganancias
rm(dtrain)
rm(parametros)
gc()
for (modelo_rank in PARAM$modelos_rank) {
imodelo <- imodelo + 1L
cat("\nmodelo_rank: ", modelo_rank, ", semillas: ")
OUTPUT$status$modelo_rank <- modelo_rank
parametros <- as.list(copy(tb_log[modelo_rank]))
iteracion_bayesiana <- parametros$iteracion_bayesiana
# creo CADA VEZ el dataset de lightgbm
dtrain <- lgb.Dataset(
data = data.matrix(dataset[, campos_buenos, with = FALSE]),
label = dataset[, clase01],
weight = dataset[, ifelse(clase_ternaria %in% c("BAJA+2"), 1.0000001, 1.0)],
free_raw_data = FALSE
)
ganancia <- parametros$ganancia
# elimino los parametros que no son de lightgbm
parametros$experimento <- NULL
parametros$cols <- NULL
parametros$rows <- NULL
parametros$fecha <- NULL
parametros$estimulos <- NULL
parametros$ganancia <- NULL
parametros$iteracion_bayesiana <- NULL
#  parametros$num_iterations  <- 10  # esta linea es solo para pruebas
if (future_con_clase) {
tb_ganancias <-
as.data.table(list("envios" = 1:1:PARAM$graficar$envios_hasta))
tb_ganancias[, gan_sum := 0.0]
}
sem <- 0L
for (vsemilla in PARAM$semillas)
{
sem <- sem + 1L
cat(sem, " ")
OUTPUT$status$sem <- sem
GrabarOutput()
# Utilizo la semilla definida en este script
parametros$seed <- vsemilla
nombre_raiz <- paste0(
sprintf("%02d", modelo_rank),
"_",
sprintf("%03d", iteracion_bayesiana),
"_s",
parametros$seed
)
arch_modelo <- paste0(
"modelo_",
#	  PARAM$version,"_",
nombre_raiz,
".model"
)
# genero el modelo entrenando en los datos finales
set.seed(parametros$seed, kind = "L'Ecuyer-CMRG")
modelo_final <- lightgbm(
data = dtrain,
param = parametros,
verbose = -100
)
# grabo el modelo, achivo .model
lgb.save(modelo_final,
file = arch_modelo
)
# creo y grabo la importancia de variables
tb_importancia <- as.data.table(lgb.importance(modelo_final))
fwrite(tb_importancia,
file = paste0(
"impo_",
nombre_raiz,
".txt"
),
sep = "\t"
)
# genero la prediccion, Scoring
prediccion <- predict(
modelo_final,
data.matrix(dfuture[, campos_buenos, with = FALSE])
)
tb_prediccion <-
dfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]
tb_prediccion[, prob := prediccion]
nom_pred <- paste0(
"pred_",
PARAM$version,"_",
nombre_raiz,
".csv"
)
fwrite(
tb_prediccion[, list(numero_de_cliente, foto_mes, prob, clase_ternaria)],
file = nom_pred,
sep = ","    # Tenía "\t" no se porqué
)
# genero los archivos para Kaggle
cortes <- seq(
from = PARAM$kaggle$envios_desde,
to = PARAM$kaggle$envios_hasta,
by = PARAM$kaggle$envios_salto
)
setorder(tb_prediccion, -prob)
if (!future_con_clase) {
# genero los archivos para Kaggle
for (corte in cortes)
{
tb_prediccion[, Predicted := 0L]
tb_prediccion[1:corte, Predicted := 1L]
nom_submit <- paste0(
PARAM$experimento,
"_",
nombre_raiz,
"_",
sprintf("%05d", corte),
".csv"
)
fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],
file = nom_submit,
sep = ","
)
}
}
if (future_con_clase) {
tb_prediccion[, ganancia_acum :=
cumsum(ifelse(clase_ternaria == "BAJA+2", 117000, -3000))]
tb_ganancias[, paste0("g", sem) :=
tb_prediccion[1:PARAM$graficar$envios_hasta, ganancia_acum]]
tb_ganancias[, gan_sum :=
gan_sum + tb_prediccion[1:PARAM$graficar$envios_hasta, ganancia_acum]]
}
# borro y limpio la memoria para la vuelta siguiente del for
rm(tb_prediccion)
rm(tb_importancia)
rm(modelo_final)
gc()
}
if (future_con_clase) {
qsemillas <- length(PARAM$semillas)
tb_ganancias[, gan_sum := gan_sum / qsemillas]
# calculo la mayor ganancia  SUAVIZADA
tb_ganancias[, gan_suavizada := frollmean(
x = gan_sum,
n = PARAM$graficar$ventana_suavizado,
align = "center",
na.rm = TRUE,
hasNA = TRUE
)]
ganancia_suavizada_max <- tb_ganancias[, max(gan_suavizada, na.rm = TRUE)]
vganancias_suavizadas <- c(vganancias_suavizadas, ganancia_suavizada_max)
ymax <- max(tb_ganancias, na.rm = TRUE)
campos_ganancias <- setdiff(colnames(tb_ganancias), "envios")
ymin <- min(tb_ganancias[envios >= PARAM$graficar$envios_desde, campos_ganancias, with=FALSE ],
na.rm = TRUE
)
arch_grafico <- paste0(
"modelo_",
sprintf("%02d", modelo_rank),
"_",
sprintf("%03d", iteracion_bayesiana),
".pdf"
)
pdf(arch_grafico)
plot(
x = tb_ganancias[envios >= PARAM$graficar$envios_desde, envios],
y = tb_ganancias[envios >= PARAM$graficar$envios_desde, g1],
type = "l",
col = "gray",
xlim = c(PARAM$graficar$envios_desde, PARAM$graficar$envios_hasta),
ylim = c(ymin, ymax),
main = paste0("Mejor gan prom = ", as.integer(ganancia_suavizada_max)),
xlab = "Envios",
ylab = "Ganancia",
panel.first = grid()
)
# las siguientes curvas
if (qsemillas > 1) {
for (s in 2:qsemillas)
{
lines(
x = tb_ganancias[envios >= PARAM$graficar$envios_desde, envios],
y = tb_ganancias[envios >= PARAM$graficar$envios_desde, get(paste0("g", s))],
col = "gray"
)
}
}
# finalmente la curva promedio
lines(
x = tb_ganancias[envios >= PARAM$graficar$envios_desde, envios],
y = tb_ganancias[envios >= PARAM$graficar$envios_desde, gan_sum],
col = "red"
)
dev.off()
# grabo las ganancias, para poderlas comparar con OTROS modelos
arch_ganancias <- paste0(
"ganancias_",
sprintf("%02d", modelo_rank),
"_",
sprintf("%03d", iteracion_bayesiana),
".txt"
)
fwrite(tb_ganancias,
file = arch_ganancias,
sep = "\t",
)
rm(tb_ganancias)
gc()
}
# impresion ganancias
rm(dtrain)
rm(parametros)
gc()
}
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/661_ZZ_final_V1_debug.r", echo=TRUE)
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/661_ZZ_final_V1_debug.r", echo=TRUE)
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/661_ZZ_final_V1_debug.r", echo=TRUE)
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/661_ZZ_final_V1_debug.r", echo=TRUE)
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/661_ZZ_final_V1_debug.r", echo=TRUE)
View(dfuture)
# limpio la memoria
rm(list = ls(all.names = TRUE)) # remove all objects
gc(full = TRUE) # garbage collection
require("data.table")
require("yaml")
require("lightgbm")
# Parametros del script
PARAM <- list()
PARAM$experimento <- "ZZ6611"
PARAM$exp_input <- "HT6511"
PARAM$version <- "g"
# Atencion, que cada modelos se procesa con 5 semillas, ajuste a SUS necesidades
# Que modelos quiero, segun su posicion en el ranking e la Bayesian Optimizacion, ordenado por ganancia descendente
PARAM$modelos_rank <- c(1)
# reemplazar por las propias semillas
PARAM$semillas <- c(123457)##, 150523, 370003, 737797, 910003)
PARAM$kaggle$envios_desde <- 10L
PARAM$kaggle$envios_hasta <- 800L
PARAM$kaggle$envios_salto <- 50L
# para el caso que deba graficar
PARAM$graficar$envios_desde <- 10L
PARAM$graficar$envios_hasta <- 500L
PARAM$graficar$ventana_suavizado <- 51L
PARAM$home <- "D:\\DOCS\\Cursos\\DS\\Lab1\\Codigo\\labo2023ba\\"
OUTPUT <- list()
options(error = function() {
traceback(20)
options(error = NULL)
stop("exiting after script error")
})
GrabarOutput <- function() {
write_yaml(OUTPUT, file = "output.yml") # grabo OUTPUT
}
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# Aqui empieza el programa
OUTPUT$PARAM <- PARAM
OUTPUT$time$start <- format(Sys.time(), "%Y%m%d %H%M%S")
base_dir <- PARAM$home
# creo la carpeta donde va el experimento
dir.create(paste0(base_dir, "exp/", PARAM$experimento, "/"),
showWarnings = FALSE
)
# Establezco el Working Directory DEL EXPERIMENTO
setwd(paste0(base_dir, "exp/", PARAM$experimento, "/"))
GrabarOutput()
write_yaml(PARAM, file = "parametros.yml") # escribo parametros utilizados
# leo la salida de la optimizaciob bayesiana
arch_log <- paste0(base_dir, "exp/", PARAM$exp_input, "/BO_log.txt")
tb_log <- fread(arch_log)
setorder(tb_log, -ganancia)
# leo el nombre del expermento de la Training Strategy
arch_TS <- paste0(base_dir, "exp/", PARAM$exp_input, "/TrainingStrategy.txt")
TS <- readLines(arch_TS, warn = FALSE)
# leo el dataset donde voy a entrenar el modelo final
arch_dataset <- paste0(base_dir, "exp/", TS, "/dataset_train_final.csv.gz")
dataset <- fread(arch_dataset)
# leo el dataset donde voy a aplicar el modelo final
arch_future <- paste0(base_dir, "exp/", TS, "/dataset_future_",PARAM$version,".csv.gz")
dfuture <- fread(arch_future)
View(dfuture)
PARAM$version <- "k"
# leo el dataset donde voy a aplicar el modelo final
arch_future <- paste0(base_dir, "exp/", TS, "/dataset_future_",PARAM$version,".csv.gz")
dfuture <- fread(arch_future)
View(dfuture)
PARAM$final_train <- c(
202107, 202106, 202105, 202104, 202103, 202102,
202101, 202012, 202011, 202010, 202009, 202008, 202002, 202001, 201912,
201911, 201910, 201909
)
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/641_TS_training_strategy_V1.r", echo=TRUE)
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/661_ZZ_final_V1_debug.r", echo=TRUE)
source("D:/DOCS/Cursos/DS/Lab1/Codigo/labo2023ba/src/workflow-inicial/661_ZZ_final_V1_debug.r", echo=TRUE)
